{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to NLP-1",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMCW8B4GMQrxXi6WCHl+2Kz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajeevBhadola/myrepo/blob/master/Intro_to_NLP_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXTlVp39JQH0"
      },
      "source": [
        "**1. Step 1- Download nltk Lib**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEpc8pi0uNnH"
      },
      "source": [
        "import nltk\n",
        "nltk.download('book')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huJCv75KJeCe"
      },
      "source": [
        "**2. Step 2- Import urllib and import html page**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-rHuHjNuPeZ"
      },
      "source": [
        "import urllib.request\n",
        "response = urllib.request.urlopen('https://www.indiatoday.in/news.html')\n",
        "html=response.read()\n",
        "print(html)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zsoLW6xJuPO"
      },
      "source": [
        "**3. Step 3- Import BeautifulSoup lib and use it to pull data from html **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-DE5gOjv7U1"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(html, 'html5lib') \n",
        "text = soup.get_text(strip=True)\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NSmpMjpKi_5"
      },
      "source": [
        "**4. Step 4 - Tokenize the text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZraBNlDVwjbh"
      },
      "source": [
        "tokens = [t for t in text.split()]\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkGdVH8WKq1J"
      },
      "source": [
        "**5. Step 5 - Count the tokens and create Freqdist of 20 most appearing tokens **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8OWWDm8zPRJ"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "sr= stopwords.words('english')\n",
        "clean_tokens = tokens[:]\n",
        "for token in tokens:\n",
        "  if token in stopwords.words('english'):\n",
        "    clean_tokens.remove(token)\n",
        "freq = nltk.FreqDist(clean_tokens)\n",
        "for key,val in freq.items():\n",
        "  print(str(key) + ':' + str(val))\n",
        "freq.plot(20, cumulative=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAygF7EizYtD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}